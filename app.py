import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import os
from sklearn.linear_model import LinearRegression

st.set_page_config(page_title="AI Startup Bubble Detector", layout="wide")

st.markdown("""
<style>
    .stDataFrame {font-size: 1.1rem;}
    div[data-testid="stMetricValue"] {font-size: 1.8rem;}
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_and_process_data():
    file_path = 'data/processed_data.csv'
    
    if os.path.exists(file_path):
        df = pd.read_csv(file_path)
    else:
        return None

    df['date'] = pd.to_datetime(df['date']).dt.date
    df['hype_display'] = df['hype_score'] * 100
    df['moat_display'] = df['moat_score'] * 100
    df['risk_score'] = (df['hype_display'] * 0.6) + ((100 - df['moat_display']) * 0.4)
    
    return df

df_raw = load_and_process_data()

if df_raw is None:
    st.error("âŒ Data not found. Please run nlp_engine.py first.")
    st.stop()

# ==========================================
# ä¾§è¾¹æ æ§åˆ¶
# ==========================================
st.sidebar.header("ğŸ•¹ï¸ Control Panel")

# å…¬å¸é€‰æ‹©
all_companies = df_raw['company'].unique()
selected_companies = st.sidebar.multiselect(
    "Select Competitors",
    options=all_companies,
    default=all_companies 
)

# ğŸ”¥ åŠŸèƒ½ 3: é£é™©è¿‡æ»¤å™¨
st.sidebar.markdown("---")
risk_filter = st.sidebar.slider(
    "ğŸšï¸ Filter by Risk Score",
    min_value=0, 
    max_value=100, 
    value=(0, 100),
    help="Only show companies within this risk range"
)

# åº”ç”¨ç­›é€‰
df_filtered = df_raw[
    (df_raw['company'].isin(selected_companies)) &
    (df_raw['risk_score'] >= risk_filter[0]) &
    (df_raw['risk_score'] <= risk_filter[1])
]

if len(df_filtered) == 0:
    st.warning("âš ï¸ No companies match your filters. Try adjusting the risk range.")
    st.stop()

# ==========================================
# æ•°æ®èšåˆ
# ==========================================
df_daily = df_filtered.groupby(['company', 'date'])[['risk_score', 'hype_display', 'moat_display', 'sentiment_score']].mean().reset_index()

# è®¡ç®—è¶‹åŠ¿
df_daily.sort_values(['company', 'date'], inplace=True)
df_daily['risk_change_7d'] = df_daily.groupby('company')['risk_score'].diff(periods=7)
df_daily['risk_change_pct'] = df_daily.groupby('company')['risk_score'].pct_change(periods=7) * 100

# ğŸ”¥ åŠŸèƒ½ 5: é¢„æµ‹å‡½æ•°
def predict_next_7d(company_data):
    """ä½¿ç”¨çº¿æ€§å›å½’é¢„æµ‹ 7 å¤©åçš„é£é™©åˆ†"""
    if len(company_data) < 7:  # æ•°æ®ä¸è¶³
        return np.nan
    
    # åªç”¨æœ€è¿‘ 30 å¤©çš„æ•°æ®ï¼ˆé¿å…é•¿æœŸè¶‹åŠ¿å¹²æ‰°ï¼‰
    recent_data = company_data.tail(30)
    
    X = np.arange(len(recent_data)).reshape(-1, 1)
    y = recent_data['risk_score'].values
    
    try:
        model = LinearRegression().fit(X, y)
        next_7d = model.predict([[len(recent_data) + 7]])[0]
        return max(0, min(100, next_7d))  # é™åˆ¶åœ¨ 0-100
    except:
        return np.nan

def get_trend_arrow(val):
    if pd.isna(val): 
        return 'âšª -'
    if val > 5:
        return f'ğŸ”´ â†‘{val:.1f}%'
    if val < -5: 
        return f'ğŸŸ¢ â†“{val:.1f}%'
    return f'âšª â‰ˆ{val:.1f}%'

df_latest = df_daily.groupby('company').tail(1).sort_values('risk_score', ascending=False)
df_latest['Trend (7d)'] = df_latest['risk_change_pct'].apply(get_trend_arrow)

# ğŸ”¥ åŠŸèƒ½ 5: æ·»åŠ é¢„æµ‹åˆ—
df_latest['Predicted (7d)'] = df_latest.apply(
    lambda row: predict_next_7d(df_daily[df_daily['company'] == row['company']]),
    axis=1
)

# ==========================================
# ä¸»ç•Œé¢
# ==========================================
st.title("ğŸ«§ AI Startup Bubble Detector")
st.markdown("Quantifying the gap between **Market Hype** and **Technical Moat**.")

# ğŸ”¥ åŠŸèƒ½ 1: æ•°æ®æ›´æ–°æ—¶é—´
latest_date = df_daily['date'].max()
st.caption(f"ğŸ“… Data last updated: **{latest_date}** | Tracking **{len(df_latest)}** companies")

st.subheader("ğŸš¨ Bubble Risk Leaderboard")

def highlight_risk(val):
    if val > 55:
        return 'background-color: rgba(255, 0, 0, 0.2)'
    elif val < 45:
        return 'background-color: rgba(0, 255, 0, 0.2)'
    return ''

# ç»„ç»‡æ’è¡Œæ¦œåˆ—ï¼ˆåŒ…å«é¢„æµ‹ï¼‰
display_cols = df_latest[['company', 'risk_score', 'Trend (7d)', 'Predicted (7d)', 'hype_display', 'moat_display']]
display_cols.columns = ['Company', 'Risk Score', '7-Day Trend', 'Forecast (7d)', 'Hype Prob (%)', 'Moat Prob (%)']

st.dataframe(
    display_cols.set_index('Company').style.map(highlight_risk, subset=['Risk Score']),
    use_container_width=True
)

# ğŸ”¥ åŠŸèƒ½ 2: ä¸‹è½½æŠ¥å‘ŠæŒ‰é’®
csv = display_cols.to_csv(index=True).encode('utf-8')
st.download_button(
    label="ğŸ“¥ Download Risk Report (CSV)",
    data=csv,
    file_name=f'bubble_risk_report_{latest_date}.csv',
    mime='text/csv',
)

st.divider()

# ==========================================
# è±¡é™å›¾
# ==========================================
col1, col2 = st.columns([3, 1])

with col1:
    st.subheader("ğŸ¯ Market Quadrant")
    
    x_min, x_max = df_latest['moat_display'].min(), df_latest['moat_display'].max()
    y_min, y_max = df_latest['hype_display'].min(), df_latest['hype_display'].max()
    x_padding = max((x_max - x_min) * 0.15, 5)
    y_padding = max((y_max - y_min) * 0.15, 5)
    
    median_hype = df_latest['hype_display'].median()
    median_moat = df_latest['moat_display'].median()

    fig_quad = px.scatter(
        df_latest, 
        x='moat_display', 
        y='hype_display', 
        color='company', 
        size='risk_score', 
        size_max=50,
        text='company',
        labels={'moat_display': 'Tech Moat Prob (%)', 'hype_display': 'Market Hype Prob (%)'},
    )
    
    fig_quad.add_hline(y=median_hype, line_dash="dash", line_color="red", opacity=0.6,
                       annotation_text=f"Median Hype ({median_hype:.1f}%)", annotation_position="right")
    fig_quad.add_vline(x=median_moat, line_dash="dash", line_color="green", opacity=0.6,
                       annotation_text=f"Median Moat ({median_moat:.1f}%)", annotation_position="top")
    
    fig_quad.update_layout(
        xaxis_range=[max(0, x_min - x_padding), min(100, x_max + x_padding)],
        yaxis_range=[max(0, y_min - y_padding), min(100, y_max + y_padding)]
    )
    st.plotly_chart(fig_quad, use_container_width=True)

with col2:
    st.info(f"""
    **Quadrant Guide:**
    - ğŸ”´ Above median hype
    - ğŸŸ¢ Above median moat
    - Lines = peer group medians
    """)

# ==========================================
# æ—¶åºå›¾
# ==========================================
# æ›¿æ¢åŸæ¥çš„æ—¶åºå›¾ä»£ç ï¼ˆå¤§çº¦ç¬¬ 160-180 è¡Œï¼‰
# ==========================================
# æ—¶åºå›¾ï¼ˆä» "st.subheader" å¼€å§‹æ›¿æ¢åˆ° "st.plotly_chart" ç»“æŸï¼‰
# ==========================================
st.subheader("ğŸ“ˆ Historical Trend")

# Debug ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œæ£€æŸ¥å®Œå¯ä»¥åˆ é™¤ï¼‰
st.write("Debug: æ•°æ®æ—¥æœŸèŒƒå›´")
st.write(f"æœ€æ—©æ—¥æœŸ: {df_daily['date'].min()}")
st.write(f"æœ€æ™šæ—¥æœŸ: {df_daily['date'].max()}")

risk_min = df_daily['risk_score'].quantile(0.01)
risk_max = df_daily['risk_score'].quantile(0.99)
risk_padding = (risk_max - risk_min) * 0.1

# ==========================================
# æ—¶åºå›¾
# ==========================================
st.subheader("ğŸ“ˆ Historical Trend")

risk_min = df_daily['risk_score'].quantile(0.01)
risk_max = df_daily['risk_score'].quantile(0.99)
risk_padding = (risk_max - risk_min) * 0.1

# åˆ›å»ºæŠ˜çº¿å›¾
fig_trend = px.line(
    df_daily, 
    x='date', 
    y='risk_score', 
    color='company',
    markers=True,
    title="Bubble Risk Score Over Time"
)

fig_trend.update_yaxes(range=[risk_min - risk_padding, risk_max + risk_padding])
fig_trend.update_traces(connectgaps=True)

# ğŸ”¥ ä¿®å¤ï¼šç”¨ add_shape æ›¿ä»£ add_vline
events = {
    '2024-12-10': 'Gemini 2.0 Flash',
    '2025-01-15': 'DeepSeek R1',
}

for date_str, event_name in events.items():
    try:
        # è½¬æ¢ä¸º datetime å¯¹è±¡ç”¨äºæ¯”è¾ƒ
        event_date = pd.to_datetime(date_str).date()
        
        # æ£€æŸ¥æ˜¯å¦åœ¨æ•°æ®èŒƒå›´å†…
        if df_daily['date'].min() <= event_date <= df_daily['date'].max():
            # ğŸ”¥ æ–¹æ³• 1ï¼šä½¿ç”¨ add_shape ç”»ç«–çº¿ï¼ˆæœ€ç¨³å®šï¼‰
            fig_trend.add_shape(
                type="line",
                x0=date_str,  # å¼€å§‹ä½ç½®
                x1=date_str,  # ç»“æŸä½ç½®ï¼ˆåŒä¸€ä½ç½®å°±æ˜¯ç«–çº¿ï¼‰
                y0=0,         # Y è½´åº•éƒ¨ï¼ˆç›¸å¯¹åæ ‡ï¼‰
                y1=1,         # Y è½´é¡¶éƒ¨ï¼ˆç›¸å¯¹åæ ‡ï¼‰
                yref="paper", # ä½¿ç”¨ç›¸å¯¹åæ ‡ç³»ç»Ÿ
                line=dict(
                    color="red",
                    width=2,
                    dash="dash"
                ),
                layer="below"  # ç”»åœ¨æ•°æ®çº¿ä¸‹æ–¹
            )
            
            # ğŸ”¥ æ–¹æ³• 2ï¼šå•ç‹¬æ·»åŠ æ ‡æ³¨æ–‡å­—
            fig_trend.add_annotation(
                x=date_str,
                y=1.05,        # åœ¨å›¾è¡¨é¡¶éƒ¨ç¨å¾®ä¸Šæ–¹
                yref="paper",  # ç›¸å¯¹åæ ‡
                text=event_name,
                showarrow=False,
                font=dict(size=10, color="red", family="Arial"),
                bgcolor="rgba(255, 255, 255, 0.9)",  # ç™½è‰²åŠé€æ˜èƒŒæ™¯
                bordercolor="red",
                borderwidth=1
            )
            
            st.write(f"âœ… å·²æ·»åŠ äº‹ä»¶æ ‡æ³¨: {event_name}")
    except Exception as e:
        st.write(f"âš ï¸ æ— æ³•æ·»åŠ äº‹ä»¶: {event_name} ({str(e)})")

st.plotly_chart(fig_trend, use_container_width=True)

# æ·»åŠ æŠ•èµ„äººè§†è§’è§£è¯»
st.info("""
**ğŸ“Š Pattern Recognition Guide:**
- **ğŸš€ Narrative Explosion**: Cold start â†’ Sudden hype = Early speculation (AI Agents pattern)
- **ğŸ’ Value Window**: Moat > Hype = Best entry point (DeepSeek Sept 2025)
- **âš ï¸ Chronic Volatility**: Persistent debate = Structural uncertainty (LangChain pattern)
- **ğŸ›¡ï¸ Moat Strengthens**: Hype â†“ + Moat â†‘ = Defensive position (Google Gemini)
""")

# å¯æŠ˜å çš„äº‹ä»¶æ—¶é—´è½´
with st.expander("ğŸ—“ï¸ Timeline: Major AI Events (Context)"):
    st.markdown("""
    | Date | Event | Impact on Market |
    |------|-------|------------------|
    | **2024-12-10** | Gemini 2.0 Flash released | âœ… Google moat strengthens |
    | **2025-01-15** | DeepSeek R1 launch | ğŸ’ Technical validation â†’ Mass adoption |
    
    *Source: Hacker News comment volume & sentiment analysis*
    """)

# ==========================================
# é¡µè„š
# ==========================================
st.markdown("---")
st.caption("Built with Streamlit â€¢ Data from Hacker News via Algolia API â€¢ NLP powered by DistilBERT")

